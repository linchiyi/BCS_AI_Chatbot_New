import csv
import io
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict

import streamlit as st
from dotenv import load_dotenv
from openai import AuthenticationError, OpenAI

from patient_context_engine import PatientContextEngine

try:
    import pandas as pd
except ImportError:  # pragma: no cover - optional dependency
    pd = None

# =========================================================
# 1ï¸âƒ£ é é¢èˆ‡æ¨£å¼è¨­å®š
# =========================================================
st.set_page_config(
    page_title="AI é†«ç—…å°è©±",
    page_icon="ğŸ§‘â€âš•ï¸",
    layout="centered",
    initial_sidebar_state="expanded",
)


def load_css(file_name: str) -> None:
    try:
        with open(file_name, encoding="utf-8") as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    except FileNotFoundError:
        pass


load_css("styles/main.css")

# =========================================================
# 2ï¸âƒ£ OpenAI Client èˆ‡ Context Engine
# =========================================================
load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")
MODEL_NAME = os.getenv("PATIENT_MODEL", "gpt-4o-mini")
EMBEDDING_MODEL = os.getenv("PATIENT_EMBEDDING_MODEL", "text-embedding-3-large")
EVALUATION_MODEL = os.getenv("PATIENT_EVALUATION_MODEL", "gpt-4.1")

if not API_KEY:
    st.error("âŒ æ‰¾ä¸åˆ° OPENAI_API_KEYã€‚è«‹å»ºç«‹ .env ä¸¦è¨­å®šé‡‘é‘°ã€‚")
    st.stop()

try:
    client = OpenAI(api_key=API_KEY)
except Exception as exc:
    st.error(f"åˆå§‹åŒ– OpenAI client å¤±æ•—ï¼š{exc}")
    st.stop()

PROJECT_ROOT = Path(__file__).resolve().parent
DEFAULT_SCRIPT_FILES = [
    PROJECT_ROOT.parent / "llm_medical_simulator" / "é†«ä¸‰-äº”å¹´ç´šçš„å°è©±è…³æœ¬_1.txt",
    PROJECT_ROOT.parent / "llm_medical_simulator" / "é†«ä¸‰-äº”å¹´ç´šçš„å°è©±è…³æœ¬_2.txt",
]
DEFAULT_TRANSCRIPTS_DIR = PROJECT_ROOT.parent / "llm_medical_simulator" / "é€å­—ç¨¿_cleaned"


@st.cache_resource(show_spinner=False)
def load_context_engine() -> PatientContextEngine:
    existing_scripts = [path for path in DEFAULT_SCRIPT_FILES if path.exists()]
    return PatientContextEngine(
        script_paths=existing_scripts,
        transcripts_dir=DEFAULT_TRANSCRIPTS_DIR if DEFAULT_TRANSCRIPTS_DIR.exists() else None,
        transcript_limit=4,
        transcript_chars=1600,
    )


context_engine = load_context_engine()

# =========================================================
# 3ï¸âƒ£ ç—…æ‚£è³‡æ–™èˆ‡æƒ…ç·’æ¨¡å¼
# =========================================================
PATIENT_PERSONA = {
    "demographics": {
        "name": "å³å®—æ˜",
        "age": 55,
        "gender": "ç”·æ€§",
    },
    "medical_history": {
        "presenting_symptoms": ["æŒçºŒé¼»å¡", "æœ‰ç—°", "ç—°ä¸­æœ‰è¡€çµ²"],
        "diagnosis": "é¼»å’½éƒ¨è§’åŒ–é±—ç‹€ç´°èƒç™Œ",
        "diagnosis_simplified": "é¼»å’½ç™Œ",
        "family_history": "å”çˆ¶58æ­²å› é¼»å’½ç™Œéä¸–",
        "children": "å…©å€‹å…’å­ (20æ­²ã€18æ­²)",
    },
}

EMOTION_MODES: Dict[str, Dict[str, str]] = {
    "æ¥µåº¦éœ‡é©šå¦èªå‹": {
        "emoji": "ğŸ˜±",
        "description": "ç—…äººæ¥µåº¦éœ‡é©šï¼Œå¼·çƒˆå¦èªè¨ºæ–·ï¼Œæƒ…ç·’æ¿€å‹•",
        "behavior": "- åè¦†è³ªç–‘å ±å‘Šæ­£ç¢ºæ€§\n- èªç„¡å€«æ¬¡ã€æ‹’çµ•æ¥å—ç™Œç—‡è³‡è¨Š",
        "temperature": 0.9,
    },
    "ææ‡¼æ“”æ†‚å‹": {
        "emoji": "ğŸ˜°",
        "description": "ç—…äººæ¥å—è¨ºæ–·ä½†æ¥µåº¦ææ‡¼ï¼Œèšç„¦é å¾Œèˆ‡å®¶äºº",
        "behavior": "- åè¦†è©¢å•å­˜æ´»ç‡èˆ‡æ²»ç™‚å‰¯ä½œç”¨\n- æ“”å¿ƒæˆç‚ºå®¶äººè² æ“”",
        "temperature": 0.75,
    },
    "å†·éœç†æ€§å‹": {
        "emoji": "ğŸ¤”",
        "description": "ç—…äººåŠªåŠ›ä¿æŒå†·éœï¼Œç†æ€§æ€è€ƒæ²»ç™‚è¨ˆç•«",
        "behavior": "- è©¢å•æ²»ç™‚æµç¨‹ã€è²»ç”¨èˆ‡æˆåŠŸç‡\n- èªæ°£å¹³ç©©ä½†å¸¶è‘—å£“åŠ›",
        "temperature": 0.55,
    },
    "æ‚²å‚·æ²®å–ªå‹": {
        "emoji": "ğŸ˜¢",
        "description": "ç—…äººæ¥µåº¦æ‚²å‚·ï¼Œè¦ºå¾—äººç”Ÿå¤±å»å¸Œæœ›",
        "behavior": "- å¸¸å‡ºç¾ç„¡åŠ›èˆ‡è‡ªè²¬çš„èªå¥\n- éœ€è¦æƒ…ç·’å®‰æ’«èˆ‡é™ªä¼´",
        "temperature": 0.65,
    },
    "æ†¤æ€’è³ªç–‘å‹": {
        "emoji": "ğŸ˜ ",
        "description": "ç—…äººæ†¤æ€’è³ªç–‘é†«ç™‚é«”ç³»èˆ‡æª¢æŸ¥çµæœ",
        "behavior": "- èªæ°£å¼·ç¡¬ï¼Œå¯èƒ½æŒ‡è²¬é†«ç™‚ç–å¤±",
        "temperature": 0.85,
    },
    "æ¥å—é…åˆå‹": {
        "emoji": "ğŸ’ª",
        "description": "ç—…äººæ¥å—äº‹å¯¦ï¼Œæº–å‚™ç©æ¥µé¢å°æ²»ç™‚",
        "behavior": "- è¨è«–é…åˆäº‹é …èˆ‡ç”Ÿæ´»å®‰æ’",
        "temperature": 0.6,
    },
}

STAGE_GUIDANCE = {
    "å»ºç«‹é—œä¿‚": "å°ˆæ³¨æ–¼ç—‡ç‹€æè¿°ã€åˆæ­¥æƒ…ç·’åæ‡‰èˆ‡å°æœªçŸ¥çš„ç„¦æ…®ã€‚",
    "èªªæ˜è§£é‡‹": "èšç„¦æ–¼å°ç™Œç—‡è¨ºæ–·çš„éœ‡é©šã€ææ‡¼ã€è³‡è¨Šéœ€æ±‚èˆ‡å®¶äººç›¸é—œå•é¡Œã€‚",
    "ç¸½çµå°è©±": "å¼·èª¿æ²»ç™‚å®‰æ’ã€ç”Ÿæ´»èª¿æ•´ã€æ”¯æŒç³»çµ±èˆ‡æƒ…ç·’æ”¶æŸã€‚",
}

STAGE_SAFEGUARDS = {
    "å»ºç«‹é—œä¿‚": "é†«å­¸ç”Ÿå°šæœªæ­éœ²æª¢æŸ¥çµæœæ™‚ï¼Œåªèƒ½æè¿°ç—‡ç‹€ã€èº«é«”ä¸é©èˆ‡ä¸å®‰ï¼›ä¸å¾—ä¸»å‹•è«‡è«–ç™Œç—‡ã€å ±å‘Šæˆ–æ²»ç™‚ã€‚",
    "èªªæ˜è§£é‡‹": "è‹¥é†«å­¸ç”Ÿå°šæœªæ˜ç¢ºèªªå‡ºç™Œç—‡æˆ–æª¢æŸ¥çµæœï¼Œä»é ˆä»¥ç–‘æƒ‘æˆ–ç„¦æ…®æ–¹å¼è©¢å•ï¼Œè€Œéç›´æ¥è¡¨ç¤ºå·²è¢«è¨ºæ–·ã€‚",
    "ç¸½çµå°è©±": "ä»éœ€éµå®ˆå‰è¿°åŸå‰‡ï¼šåªæœ‰åœ¨é†«å­¸ç”Ÿå·²èªªæ˜ç™Œç—‡å¾Œï¼Œæ‰å¯å°±æ²»ç™‚èˆ‡é å¾Œè¡¨é”æ“”æ†‚ã€‚",
}

EVALUATION_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½ç¶“é©—è±å¯Œçš„ OSCE ä¸»è€ƒå®˜ï¼Œè² è²¬è©•ä¼°é†«å­¸ç”Ÿèˆ‡æ¨™æº–åŒ–ç—…äººçš„å®Œæ•´å°è©±é€å­—ç¨¿ã€‚
è«‹ä¾ 12 é …æ¨™æº–åŒ–è©•åˆ†æŒ‡æ¨™é€²è¡Œé‡åŒ–è©•åˆ†ï¼Œä¸¦æä¾›æ•´é«”å›é¥‹ã€‚

è©•åˆ†è¦ç¯„ï¼š
- æ¯ä¸€é … `score` å¿…é ˆç‚º 0ï¼ˆæœªé”æ¨™ï¼‰ã€1ï¼ˆéƒ¨åˆ†é”æ¨™ï¼‰ã€æˆ– 2ï¼ˆå®Œå…¨é”æ¨™ï¼‰ã€‚
- `rating_1_to_5.score` èˆ‡ `rating_1_to_3.score` ä¹Ÿéœ€ç‚ºæ•´æ•¸ã€‚
- åƒ…è¼¸å‡ºå–®ä¸€ JSON ç‰©ä»¶ï¼Œä¸å¾—é™„åŠ èªªæ˜æ–‡å­—ã€Markdown æˆ–å¤šé¤˜æ¨™é»ã€‚
- `overall_performance.total_score` ä¿æŒç‚º nullï¼Œæˆ‘å€‘æœƒåœ¨å¤–éƒ¨è‡ªå‹•è¨ˆç®—ã€‚
- `brief_feedback` è«‹æä¾›ä¸è¶…é 40 å­—çš„ä¸­æ–‡é‡é»å»ºè­°ã€‚
- æ¯ä¸€é …ç›®è«‹åœ¨ `rationale` æ¬„ä½ä»¥ 15 å­—å…§èªªæ˜è©•åˆ†ç†ç”±ã€‚

è«‹ä½¿ç”¨ä»¥ä¸‹ JSON æ¨¡æ¿ï¼Œä¸¦ç¢ºä¿éµåèˆ‡çµæ§‹ä¸€è‡´ï¼š
{
    "evaluation_items": [
        {"item": "1. æœ‰ç¦®è²Œ", "detail": "å¦‚è²éŸ³æ…‹åº¦èª æ‡‡ï¼Œè‡ªæˆ‘ä»‹ç´¹ï¼Œæ³¨è¦–ç—…äºº", "score": null, "rationale": ""},
        {"item": "2. å»ºç«‹å‹å¥½é—œä¿‚", "detail": "å¦‚ç¨±å‘¼ç—…äººå§“ååŠå®¶å±¬ï¼Œæœ‰éœ€è¦ä»¥å¤–çš„å¯’æš„èªï¼Œè¡¨é”é—œå¿ƒæˆ–é«”è²¼", "score": null, "rationale": ""},
        {"item": "3. è§£é‡‹å¾—æ¸…æ¥š", "detail": "å¦‚èªªè©±é€Ÿåº¦æ…¢ï¼Œäº†è§£ç—…äººçš„ç›¸é—œèƒŒæ™¯åŠäº‹å‰è³‡è¨Šï¼Œèƒ½å°±èƒŒæ™¯çµ¦äºˆé©åˆ‡çš„å®šå°æ–¹æ¡ˆå»ºè­°", "score": null, "rationale": ""},
        {"item": "4. ç”¨å¿ƒè†è½", "detail": "å¦‚çœ¼ç›æœ‰æ³¨è¦–å°æ–¹ï¼Œè¨˜ä½å°æ–¹è¬›çš„è©±ä¸”æœ‰å›æ‡‰ï¼Œä¸æ‰“æ–·å°æ–¹è¬›è©±", "score": null, "rationale": ""},
        {"item": "5. åŒç†å¿ƒ", "detail": "å¦‚è¡¨ç¾å‡ºèƒ½äº†è§£ç—…æ‚£æ„Ÿå—èˆ‡è™•å¢ƒçš„èªè¨€æˆ–æ…‹åº¦ï¼Œé©åº¦çš„å›æ‡‰ï¼Œæä¾›æ”¯æŒ", "score": null, "rationale": ""},
        {"item": "6. è©¢å•å®¶äººæ˜¯å¦ä¸€èµ·ä¾†", "detail": "ä¸¦å‘ŠçŸ¥å¯è«‹å®¶äººä¸€èµ·åƒèˆ‡", "score": null, "rationale": ""},
        {"item": "7. æ‰¿è«¾ç›¡å¿ƒç…§é¡§åŠé¿å…éåº¦çš„ä¿è­‰", "score": null, "rationale": ""},
        {"item": "8. ä»¥æ²‰é»˜è™•ç†æ²‰é»˜åŠå“­æ³£", "score": null, "rationale": ""},
        {"item": "9. å‘ŠçŸ¥é¼»å’½ç™Œä¹‹é å¾Œ", "score": null, "rationale": ""},
        {"item": "10. å‘ŠçŸ¥é¼»å’½ç™Œæ˜¯å¦èˆ‡éºå‚³ç›¸é—œåŠç›¸é—œå› å­", "score": null, "rationale": ""},
        {"item": "11. ç°¡è¦èªªæ˜é¼»å’½ç™Œä¸‹ä¸€æ­¥çš„æª¢æŸ¥", "score": null, "rationale": ""},
        {"item": "12. ç°¡è¦èªªæ˜é¼»å’½ç™Œä¸‹ä¸€æ­¥çš„æ²»ç™‚è¨ˆç•«", "score": null, "rationale": ""}
    ],
    "overall_performance": {
        "total_score": null,
        "rating_1_to_5": {"score": null, "description": "æ•´é«”è¡¨ç¾æ™®é€šï¼ˆ1=å·®ï¼Œ2=å¾…åŠ å¼·ï¼Œ3=æ™®é€šï¼Œ4=è‰¯å¥½ï¼Œ5=å„ªç§€ï¼‰", "reason": ""},
        "rating_1_to_3": {"score": null, "description": "æœªå¡«å¯«ï¼ˆ1=æ˜é¡¯æœªé”ï¼Œ2=åŠæ ¼åŸºç¤ï¼Œ3=æ˜é¡¯é€šéï¼‰", "reason": ""}
    },
    "brief_feedback": ""
}
"""


def _format_conversation_for_model(messages) -> str:
    lines = []
    for idx, message in enumerate(messages, start=1):
        role = "é†«å­¸ç”Ÿ" if message.get("role") == "user" else "ç—…æ‚£"
        content = message.get("content", "").strip()
        lines.append(f"{idx}. {role}: {content}")
    return "\n".join(lines)


def _call_evaluation_api(prompt_text: str) -> str:
    try:
        response = client.responses.create(
            model=EVALUATION_MODEL,
            input=[
                {
                    "role": "system",
                    "content": [{"type": "input_text", "text": EVALUATION_SYSTEM_PROMPT}],
                },
                {
                    "role": "user",
                    "content": [{"type": "input_text", "text": prompt_text}],
                },
            ],
            temperature=0.0,
        )
    except Exception as exc:
        raise RuntimeError(f"å‘¼å«è©•åˆ†æ¨¡å‹å¤±æ•—ï¼š{exc}") from exc

    collected_text: list[str] = []
    output_items = getattr(response, "output", [])
    for item in output_items:
        for content in getattr(item, "content", []):
            if getattr(content, "type", "") in {"output_text", "text"}:
                collected_text.append(getattr(content, "text", ""))

    if not collected_text and hasattr(response, "output_text"):
        collected_text.append(response.output_text)

    raw_text = "\n".join(part for part in collected_text if part).strip()
    if not raw_text:
        raise RuntimeError("è©•åˆ†æ¨¡å‹æœªè¿”å›ä»»ä½•æ–‡å­—å…§å®¹ã€‚")
    return raw_text


def _parse_evaluation_output(raw_text: str) -> Dict:
    try:
        return json.loads(raw_text)
    except json.JSONDecodeError:
        pass

    first = raw_text.find("{")
    last = raw_text.rfind("}")
    if first != -1 and last != -1 and last > first:
        candidate = raw_text[first : last + 1]
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass

    raise ValueError("ç„¡æ³•è§£æè©•åˆ†çµæœçš„ JSONã€‚åŸå§‹è¼¸å‡ºï¼š" + raw_text)


def generate_conversation_evaluation(messages) -> Dict:
    if not messages:
        raise ValueError("æ²’æœ‰å°è©±å…§å®¹å¯ä¾›è©•åˆ†ã€‚")

    meta_info = (
        f"ç—…æ‚£æƒ…ç·’æ¨¡å¼ï¼š{st.session_state.emotion_mode}\n"
        f"å°è©±éšæ®µï¼š{st.session_state.stage}\n"
        f"é†«å­¸ç”Ÿç­‰ç´šï¼šLevel {st.session_state.student_level}\n"
    )

    conversation_text = _format_conversation_for_model(messages)
    user_prompt = f"""
ä»¥ä¸‹æä¾›ä¸€æ®µé†«å­¸ç”Ÿèˆ‡æ¨™æº–åŒ–ç—…æ‚£çš„å®Œæ•´é€å­—ç¨¿ã€‚
è«‹ä¾æ“šè¦ç¯„è¼¸å‡ºå–®ä¸€ JSON ç‰©ä»¶ï¼Œå¡«å¯« 12 é …è©•åˆ†èˆ‡æ•´é«”å›é¥‹ã€‚
å‹™å¿…éµå®ˆåˆ†æ•¸è¦ç¯„ï¼Œä¸¦æ–¼ brief_feedback ä¸­æä¾› 40 å­—å…§çš„ä¸­æ–‡å»ºè­°ã€‚
å¦‚é€å­—ç¨¿æœ‰èªå¥ä¸æ•´é½Šï¼Œè«‹ä¾å°è©±èªæ„åˆ¤æ–·ã€‚

[å°è©±èƒŒæ™¯]
{meta_info}
[é€å­—ç¨¿]
{conversation_text}
"""

    raw_output = _call_evaluation_api(user_prompt)
    structured = _parse_evaluation_output(raw_output)

    try:
        items = structured.get("evaluation_items", [])
        if isinstance(items, list):
            total = 0
            for item in items:
                if isinstance(item, dict):
                    score = item.get("score")
                    if isinstance(score, (int, float)):
                        item["score"] = int(score)
                        total += int(score)
                    else:
                        item["score"] = 0 if score is None else score
            overall = structured.setdefault("overall_performance", {})
            if isinstance(overall, dict):
                overall["total_score"] = total
    except Exception:
        pass

    return {
        "raw_text": raw_output,
        "structured": structured,
    }


def request_evaluation() -> None:
    st.session_state.pending_evaluation = True

# =========================================================
# 4ï¸âƒ£ Session State åˆå§‹å€¼
# =========================================================
if "messages" not in st.session_state:
    st.session_state.messages = []
if "emotion_mode" not in st.session_state:
    st.session_state.emotion_mode = "ææ‡¼æ“”æ†‚å‹"
if "stage" not in st.session_state:
    st.session_state.stage = PatientContextEngine.STAGE_ORDER[0]
if "student_level" not in st.session_state:
    st.session_state.student_level = 3
if "last_evaluation" not in st.session_state:
    st.session_state.last_evaluation = None
if "last_evaluation_error" not in st.session_state:
    st.session_state.last_evaluation_error = None
if "pending_evaluation" not in st.session_state:
    st.session_state.pending_evaluation = False

# =========================================================
# 5ï¸âƒ£ å·¥å…·å‡½å¼
# =========================================================

def compose_system_prompt(stage: str, latest_user_text: str) -> str:
    emotion_mode = st.session_state.emotion_mode
    level = st.session_state.student_level
    emotion_config = EMOTION_MODES[emotion_mode]

    context_block = context_engine.build_context_block(
        level=level,
        stage=stage,
        emotion_mode=emotion_mode,
        transcript_chars=1800,
        query_text=latest_user_text,
        embedding_client=client,
        embedding_model=EMBEDDING_MODEL,
    )

    persona = PATIENT_PERSONA["demographics"]
    history = PATIENT_PERSONA["medical_history"]

    safeguard = STAGE_SAFEGUARDS.get(stage, "")

    return f"""
### è§’è‰²è¨­å®š
ä½ æ˜¯ {persona['name']}ï¼Œ{persona['age']} æ­² {persona['gender']}ï¼Œå‰›æ”¶åˆ°é¼»å’½ç™Œç—…ç†å ±å‘Šçš„ç—…äººã€‚é†«å­¸ç”Ÿç‚º Level {level} å­¸å“¡ï¼Œæ­£å‘ä½ èªªæ˜å£æ¶ˆæ¯ã€‚

### ç•¶å‰æºé€šéšæ®µ
- éšæ®µï¼š{stage}
- æŒ‡å¼•ï¼š{STAGE_GUIDANCE.get(stage, '')}
- éšæ®µå®‰å…¨å®ˆå‰‡ï¼š{safeguard}
- æƒ…ç·’æ¨¡å¼ï¼š{emotion_mode}ï¼ˆ{emotion_config['description']}ï¼‰
- è¡Œç‚ºç‰¹å¾µï¼š{emotion_config['behavior']}

### èªæ–™åƒè€ƒï¼ˆè«‹æ¨¡ä»¿èªæ°£ã€ç¯€å¥èˆ‡å­—è©é¸æ“‡ï¼‰
{context_block}

### å›è¦†åŸå‰‡
1. åƒ…ä»¥ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¿æŒæƒ…ç·’æ¨¡å¼ä¸€è‡´ã€‚
2. æ¯æ¬¡å›è¦† 1-3 å¥ä¸”40å­—ä»¥å…§ç‚ºä¸»ï¼Œå¿…è¦æ™‚å¯å»¶ä¼¸æå•æˆ–æè¿°èº«å¿ƒæ„Ÿå—ã€‚
4. è‹¥é†«å­¸ç”Ÿçµ¦å‡ºç©ºæ´ä¿è­‰ï¼Œä¾æƒ…ç·’æ¨¡å¼åšå‡ºç›¸æ‡‰åæ‡‰ï¼ˆè³ªç–‘ã€ææ‡¼æˆ–æ‚²å‚·ï¼‰ã€‚
5. é©æ™‚æå‡ºæ“”å¿ƒæœƒéºå‚³çµ¦å®¶äººï¼Œä¸¦ä¸”é©åº¦æåŠå®¶äººã€ç¶“æ¿Ÿè² æ“”æˆ–ç—…å‹æ”¯æŒï¼Œä»¥å¢åŠ çœŸå¯¦æ„Ÿã€‚
3. ä¸ä¸»å‹•æä¾›é†«ç™‚å»ºè­°ï¼Œå°ˆæ³¨æ–¼ç—…äººæƒ…ç·’ã€ç–‘å•èˆ‡ç”Ÿæ´»é¡§æ…®ã€‚
6. **æœªå¾é†«å­¸ç”Ÿå£ä¸­è½åˆ°æª¢æŸ¥çµæœã€ç™Œç—‡æˆ–æ²»ç™‚ç´°ç¯€å‰ï¼Œç¦æ­¢è‡ªè¡Œæ­éœ²æˆ–ç¢ºèªå·²ç½¹ç™Œï¼›å¯è¡¨é”æ“”å¿ƒæª¢æŸ¥çµæœï¼Œä½†èªæ°£éœ€ä¿æŒä¸ç¢ºå®šæ€§ã€‚**
""".strip()


def format_conversation_for_txt(messages):
    transcript = [f"æƒ…ç·’æ¨¡å¼: {st.session_state.emotion_mode}", f"éšæ®µ: {st.session_state.stage}"]
    transcript.append("=" * 50)
    for msg in messages:
        role = "é†«å­¸ç”Ÿ" if msg["role"] == "user" else "ç—…æ‚£"
        transcript.append(f"({role})\n{msg['content']}\n")
    return "\n".join(transcript)


def update_stage(user_text: str) -> None:
    current_stage = st.session_state.stage
    inferred = PatientContextEngine.infer_stage_from_text(user_text, current_stage)
    current_index = PatientContextEngine.STAGE_ORDER.index(current_stage)
    inferred_index = PatientContextEngine.STAGE_ORDER.index(inferred)
    if inferred_index > current_index:
        st.session_state.stage = PatientContextEngine.STAGE_ORDER[inferred_index]


# =========================================================
# 6ï¸âƒ£ å´é‚Šæ¬„
# =========================================================
with st.sidebar:
    st.header("âš™ï¸ åŠŸèƒ½é¸å–®")

    emotion_options = list(EMOTION_MODES.keys())
    emotion_labels = [f"{EMOTION_MODES[mode]['emoji']} {mode}" for mode in emotion_options]
    current_idx = emotion_options.index(st.session_state.emotion_mode)
    selected_label = st.selectbox("ç—…æ‚£æƒ…ç·’æ¨¡å¼", emotion_labels, index=current_idx)
    st.session_state.emotion_mode = emotion_options[emotion_labels.index(selected_label)]

    st.session_state.student_level = st.selectbox(
        "é†«å­¸ç”Ÿç­‰ç´šï¼ˆå½±éŸ¿æç¤ºèªæ–™ï¼‰",
        options=[3, 4, 5],
        index=[3, 4, 5].index(st.session_state.student_level),
    )

    st.info(
        f"ç›®å‰æºé€šéšæ®µï¼š**{st.session_state.stage}**\n\n"
        f"æŒ‡å¼•ï¼š{STAGE_GUIDANCE.get(st.session_state.stage, 'æŒçºŒè§€å¯Ÿç—…äººæƒ…ç·’')}"
    )

    if st.button("ğŸ”„ é‡æ–°é–‹å§‹å°è©±", type="primary"):
        st.session_state.messages = []
        st.session_state.stage = PatientContextEngine.STAGE_ORDER[0]
        st.session_state.last_evaluation = None
        st.session_state.last_evaluation_error = None
        st.session_state.pending_evaluation = False
        st.rerun()

    st.divider()

    if st.session_state.messages:
        transcript_bytes = format_conversation_for_txt(st.session_state.messages).encode("utf-8")
        st.download_button(
            "ğŸ“¥ ä¸‹è¼‰å°è©±ç´€éŒ„",
            data=transcript_bytes,
            file_name=f"å°è©±ç´€éŒ„_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain",
            key="download_transcript",
            on_click=request_evaluation,
        )

    # st.caption(f"ğŸ§  ä½¿ç”¨æ¨¡å‹ï¼š{MODEL_NAME}")

# =========================================================
# 7ï¸âƒ£ ä¸»ä»‹é¢
# =========================================================
st.title("ğŸ§‘â€âš•ï¸ AI é†«ç—…å°è©± - èªæ–™å¼·åŒ–ç‰ˆ")

col1, col2 = st.columns([3, 2])
with col1:
    st.markdown(
        f"""
**ğŸ‘¤ ç—…æ‚£è³‡è¨Š**  
å§“åï¼š{PATIENT_PERSONA['demographics']['name']}ï¼ˆ{PATIENT_PERSONA['demographics']['age']} æ­²ï¼Œ{PATIENT_PERSONA['demographics']['gender']}ï¼‰  
ä¸»è¨´ï¼š{', '.join(PATIENT_PERSONA['medical_history']['presenting_symptoms'])}  
å®¶æ—å²ï¼š{PATIENT_PERSONA['medical_history']['family_history']}
"""
    )
with col2:
    emotion_cfg = EMOTION_MODES[st.session_state.emotion_mode]
    st.markdown(
        f"""
**ğŸ­ æƒ…ç·’ç‹€æ…‹**  
{emotion_cfg['emoji']} **{st.session_state.emotion_mode}**  
{emotion_cfg['description']}
"""
    )

st.divider()

for msg in st.session_state.messages:
    avatar = "ğŸ§‘â€âš•ï¸" if msg["role"] == "user" else "ğŸ¤’"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

# =========================================================
# 8ï¸âƒ£ è§¸ç™¼è©•åˆ†è¨ˆç®—
# =========================================================
if st.session_state.pending_evaluation:
    if st.session_state.messages:
        with st.spinner("è©•åˆ†èˆ‡å›é¥‹ç”¢ç”Ÿä¸­..."):
            try:
                evaluation_result = generate_conversation_evaluation(st.session_state.messages)
                st.session_state.last_evaluation = {
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "structured": evaluation_result["structured"],
                    "raw_text": evaluation_result["raw_text"],
                }
                st.session_state.last_evaluation_error = None
            except Exception as exc:
                st.session_state.last_evaluation = None
                st.session_state.last_evaluation_error = str(exc)
    else:
        st.session_state.last_evaluation = None
        st.session_state.last_evaluation_error = "æ²’æœ‰å¯è©•åˆ†çš„å°è©±ã€‚"
    st.session_state.pending_evaluation = False

# =========================================================
# 9ï¸âƒ£ è©•åˆ†çµæœé¡¯ç¤º
# =========================================================
if st.session_state.last_evaluation_error:
    st.error(f"âš ï¸ ç”¢ç”Ÿè©•åˆ†æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{st.session_state.last_evaluation_error}")
elif st.session_state.last_evaluation:
    latest_eval = st.session_state.last_evaluation
    structured_eval = latest_eval.get("structured", {})
    overall = structured_eval.get("overall_performance", {}) or {}
    rating_1_to_5 = overall.get("rating_1_to_5", {}) or {}
    rating_1_to_3 = overall.get("rating_1_to_3", {}) or {}

    st.success(f"âœ… å·²æ–¼ {latest_eval['timestamp']} å®Œæˆè©•åˆ†èˆ‡å›é¥‹ã€‚")

    col_total, col_rating5, col_rating3 = st.columns(3)
    total_score = overall.get("total_score")
    col_total.metric("ç¸½åˆ†", total_score if total_score is not None else "N/A")
    col_rating5.metric(
        "1-5 ç´šæ•´é«”è©•åˆ†",
        rating_1_to_5.get("score", "N/A"),
        help=rating_1_to_5.get("description", ""),
    )
    col_rating3.metric(
        "1-3 ç´šæ•´é«”è©•åˆ†",
        rating_1_to_3.get("score", "N/A"),
        help=rating_1_to_3.get("description", ""),
    )

    brief_feedback = structured_eval.get("brief_feedback")
    if brief_feedback:
        st.info(f"å›é¥‹ï¼š{brief_feedback}")

    score_rows = []
    for item in structured_eval.get("evaluation_items", []) or []:
        if not isinstance(item, dict):
            continue
        score_value = item.get("score")
        try:
            score_value = int(score_value) if score_value is not None else None
        except (TypeError, ValueError):
            pass
        score_rows.append(
            {
                "é …ç›®": item.get("item", ""),
                "å¾—åˆ†": score_value,
                "èªªæ˜": item.get("detail", ""),
                "è©•åˆ†ç†ç”±": item.get("rationale", ""),
            }
        )

    if score_rows:
        st.subheader("é …ç›®å¾—åˆ†æ¦‚è¦½")
        if pd is not None:
            score_df = pd.DataFrame(score_rows)
            chart_series = score_df.set_index("é …ç›®")["å¾—åˆ†"].fillna(0)
            st.bar_chart(chart_series, use_container_width=True)
            st.dataframe(score_df, use_container_width=True)
        else:
            chart_data = {
                "é …ç›®": [row["é …ç›®"] for row in score_rows],
                "å¾—åˆ†": [row["å¾—åˆ†"] if row["å¾—åˆ†"] is not None else 0 for row in score_rows],
            }
            st.bar_chart(chart_data, x="é …ç›®", y="å¾—åˆ†", use_container_width=True)
            st.table(score_rows)

        csv_buffer = io.StringIO()
        csv_writer = csv.writer(csv_buffer)
        csv_writer.writerow(["é …ç›®", "å¾—åˆ†", "èªªæ˜", "è©•åˆ†ç†ç”±"])
        for row in score_rows:
            csv_writer.writerow([
                row.get("é …ç›®", ""),
                row.get("å¾—åˆ†", ""),
                row.get("èªªæ˜", ""),
                row.get("è©•åˆ†ç†ç”±", ""),
            ])

        st.download_button(
            "ğŸ“„ ä¸‹è¼‰è©•åˆ†æ˜ç´° (CSV)",
            data=csv_buffer.getvalue().encode("utf-8"),
            file_name=f"å°è©±è©•åˆ†_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
        )

    # with st.expander("æŸ¥çœ‹åŸå§‹è©•åˆ† JSON", expanded=False):
    #     st.json(structured_eval)

    # eval_download_data = json.dumps(
    #     structured_eval, ensure_ascii=False, indent=2
    # ).encode("utf-8")
    # st.download_button(
    #     "ğŸ“Š ä¸‹è¼‰è©•åˆ† JSON",
    #     data=eval_download_data,
    #     file_name=f"å°è©±è©•åˆ†_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
    #     mime="application/json",
    # )

# =========================================================
# ğŸ”Ÿ å°è©±äº’å‹•
# =========================================================
if prompt := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•è¨ºå…§å®¹..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.last_evaluation = None
    st.session_state.last_evaluation_error = None
    st.session_state.pending_evaluation = False
    update_stage(prompt)

    with st.chat_message("user", avatar="ğŸ§‘â€âš•ï¸"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="ğŸ¤’"):
        with st.spinner("ç—…æ‚£æ€è€ƒå›è¦†ä¸­..."):
            try:
                system_prompt = compose_system_prompt(st.session_state.stage, prompt)
                temperature = EMOTION_MODES[st.session_state.emotion_mode]["temperature"]
                messages = [{"role": "system", "content": system_prompt}] + st.session_state.messages

                response = client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=420,
                )

                content = response.choices[0].message.content.strip()
                st.markdown(content)
                st.session_state.messages.append({"role": "assistant", "content": content})

            except AuthenticationError:
                st.error("âŒ OpenAI API é‡‘é‘°ç„¡æ•ˆæˆ–å·²éæœŸã€‚")
            except Exception as exc:
                st.error(f"âš ï¸ å‘¼å« OpenAI API æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{exc}")

# =========================================================
# 1ï¸âƒ£1ï¸âƒ£ é å°¾è³‡è¨Š
# =========================================================
st.divider()
# st.caption(
#     f"éšæ®µï¼š{st.session_state.stage} | æƒ…ç·’æ¨¡å¼ï¼š{st.session_state.emotion_mode} | å›åˆï¼š{len(st.session_state.messages)//2}"
# )
